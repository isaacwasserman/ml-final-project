@article{cyclegan,
  author    = {Jun{-}Yan Zhu and
               Taesung Park and
               Phillip Isola and
               Alexei A. Efros},
  title     = {Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial
               Networks},
  journal   = {CoRR},
  volume    = {abs/1703.10593},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.10593},
  eprinttype = {arXiv},
  eprint    = {1703.10593},
  timestamp = {Mon, 13 Aug 2018 16:48:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ZhuPIE17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{stylegan,
  author    = {Tero Karras and
               Samuli Laine and
               Timo Aila},
  title     = {A Style-Based Generator Architecture for Generative Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1812.04948},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.04948},
  eprinttype = {arXiv},
  eprint    = {1812.04948},
  timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-04948.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{discogan,
  author    = {Taeksoo Kim and
               Moonsu Cha and
               Hyunsoo Kim and
               Jung Kwon Lee and
               Jiwon Kim},
  title     = {Learning to Discover Cross-Domain Relations with Generative Adversarial
               Networks},
  journal   = {CoRR},
  volume    = {abs/1703.05192},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.05192},
  eprinttype = {arXiv},
  eprint    = {1703.05192},
  timestamp = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KimCKLK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{rcgan,
  doi = {10.48550/ARXIV.1706.02633},
  
  url = {https://arxiv.org/abs/1706.02633},
  
  author = {Esteban, Cristóbal and Hyland, Stephanie L. and Rätsch, Gunnar},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{seqgan,
  author    = {Lantao Yu and
               Weinan Zhang and
               Jun Wang and
               Yong Yu},
  title     = {SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient},
  journal   = {CoRR},
  volume    = {abs/1609.05473},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.05473},
  eprinttype = {arXiv},
  eprint    = {1609.05473},
  timestamp = {Sun, 21 Apr 2019 10:04:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/YuZWY16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{CMU,
    title = "Pushing the Limits of Low-Resource Morphological Inflection",
    author = "Anastasopoulos, Antonios  and
      Neubig, Graham",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1091",
    doi = "10.18653/v1/D19-1091",
    pages = "984--996",
    abstract = "Recent years have seen exceptional strides in the task of automatic morphological inflection generation. However, for a long tail of languages the necessary resources are hard to come by, and state-of-the-art neural methods that work well under higher resource settings perform poorly in the face of a paucity of data. In response, we propose a battery of improvements that greatly improve performance under such low-resource conditions. First, we present a novel two-step attention architecture for the inflection decoder. In addition, we investigate the effects of cross-lingual transfer from single and multiple languages, as well as monolingual data hallucination. The macro-averaged accuracy of our models outperforms the state-of-the-art by 15 percentage points. Also, we identify the crucial factors for success with cross-lingual transfer for morphological inflection: typological similarity and a common representation across languages.",
}

@inproceedings{sigmorphon2019,
    title = "The {SIGMORPHON} 2019 Shared Task: Morphological Analysis in Context and Cross-Lingual Transfer for Inflection",
    author = "McCarthy, Arya D.  and
      Vylomova, Ekaterina  and
      Wu, Shijie  and
      Malaviya, Chaitanya  and
      Wolf-Sonkin, Lawrence  and
      Nicolai, Garrett  and
      Kirov, Christo  and
      Silfverberg, Miikka  and
      Mielke, Sabrina J.  and
      Heinz, Jeffrey  and
      Cotterell, Ryan  and
      Hulden, Mans",
    booktitle = "Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-4226",
    doi = "10.18653/v1/W19-4226",
    pages = "229--244",
    abstract = "The SIGMORPHON 2019 shared task on cross-lingual transfer and contextual analysis in morphology examined transfer learning of inflection between 100 language pairs, as well as contextual lemmatization and morphosyntactic description in 66 languages. The first task evolves past years{'} inflection tasks by examining transfer of morphological inflection knowledge from a high-resource language to a low-resource language. This year also presents a new second challenge on lemmatization and morphological feature analysis in context. All submissions featured a neural component and built on either this year{'}s strong baselines or highly ranked systems from previous years{'} shared tasks. Every participating team improved in accuracy over the baselines for the inflection task (though not Levenshtein distance), and every team in the contextual analysis task improved on both state-of-the-art neural and non-neural baselines.",
}

@misc{antoniou,
  doi = {10.48550/ARXIV.1711.04340},
  
  url = {https://arxiv.org/abs/1711.04340},
  
  author = {Antoniou, Antreas and Storkey, Amos and Edwards, Harrison},
  
  keywords = {Machine Learning (stat.ML), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Data Augmentation Generative Adversarial Networks},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@incollection{shin,
booktitle = {Simulation and Synthesis in Medical Imaging},
copyright = {Springer Nature Switzerland AG 2018},
abstract = {Data diversity is critical to success when training deep learning models. Medical imaging data sets are often imbalanced as pathologic findings are generally rare, which introduces significant challenges when training deep learning models. In this work, we propose a method to generate synthetic abnormal MRI images with brain tumors by training a generative adversarial network using two publicly available data sets of brain MRI. We demonstrate two unique benefits that the synthetic images provide. First, we illustrate improved performance on tumor segmentation by leveraging the synthetic images as a form of data augmentation. Second, we demonstrate the value of generative models as an anonymization tool, achieving comparable tumor segmentation results when trained on the synthetic data versus when trained on real subject data. Together, these results offer a potential solution to two of the largest challenges facing machine learning in medical imaging, namely the small incidence of pathological findings, and the restrictions around sharing of patient data.},
author = {Shin, Hoo-Chang and Tenenholtz, Neil A and Rogers, Jameson K and Schwarz, Christopher G and Senjem, Matthew L and Gunter, Jeffrey L and Andriole, Katherine P and Michalski, Mark},
address = {Cham},
isbn = {3030005356},
issn = {0302-9743},
keywords = {Brain tumor ; Deep learning ; GAN ; Generative models ; Image synthesis ; Magnetic resonance imaging ; MRI ; Segmentation},
language = {eng},
pages = {1-11},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {Medical Image Synthesis for Data Augmentation and Anonymization Using Generative Adversarial Networks},
year = {2018},
}

@article{pix2pix,
  author    = {Phillip Isola and
               Jun{-}Yan Zhu and
               Tinghui Zhou and
               Alexei A. Efros},
  title     = {Image-to-Image Translation with Conditional Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1611.07004},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.07004},
  eprinttype = {arXiv},
  eprint    = {1611.07004},
  timestamp = {Mon, 13 Aug 2018 16:49:05 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/IsolaZZE16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{wang,
  author    = {Guotai Wang and
               Wenqi Li and
               S{\'{e}}bastien Ourselin and
               Tom Vercauteren},
  title     = {Automatic Brain Tumor Segmentation using Cascaded Anisotropic Convolutional
               Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1709.00382},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.00382},
  eprinttype = {arXiv},
  eprint    = {1709.00382},
  timestamp = {Fri, 11 Feb 2022 16:53:28 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-00382.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{sandfort,
author={Sandfort, Veit
and Yan, Ke
and Pickhardt, Perry J.
and Summers, Ronald M.},
title={Data augmentation using generative adversarial networks (CycleGAN) to improve generalizability in CT segmentation tasks},
journal={Scientific Reports},
year={2019},
month={Nov},
day={15},
volume={9},
number={1},
pages={16884},
abstract={Labeled medical imaging data is scarce and expensive to generate. To achieve generalizable deep learning models large amounts of data are needed. Standard data augmentation is a method to increase generalizability and is routinely performed. Generative adversarial networks offer a novel method for data augmentation. We evaluate the use of CycleGAN for data augmentation in CT segmentation tasks. Using a large image database we trained a CycleGAN to transform contrast CT images into non-contrast images. We then used the trained CycleGAN to augment our training using these synthetic non-contrast images. We compared the segmentation performance of a U-Net trained on the original dataset compared to a U-Net trained on the combined dataset of original data and synthetic non-contrast images. We further evaluated the U-Net segmentation performance on two separate datasets: The original contrast CT dataset on which segmentations were created and a second dataset from a different hospital containing only non-contrast CTs. We refer to these 2 separate datasets as the in-distribution and out-of-distribution datasets, respectively. We show that in several CT segmentation tasks performance is improved significantly, especially in out-of-distribution (noncontrast CT) data. For example, when training the model with standard augmentation techniques, performance of segmentation of the kidneys on out-of-distribution non-contrast images was dramatically lower than for in-distribution data (Dice score of 0.09 vs. 0.94 for out-of-distribution vs. in-distribution data, respectively, p{\thinspace}<{\thinspace}0.001). When the kidney model was trained with CycleGAN augmentation techniques, the out-of-distribution (non-contrast) performance increased dramatically (from a Dice score of 0.09 to 0.66, p{\thinspace}<{\thinspace}0.001). Improvements for the liver and spleen were smaller, from 0.86 to 0.89 and 0.65 to 0.69, respectively. We believe this method will be valuable to medical imaging researchers to reduce manual segmentation effort and cost in CT imaging.},
issn={2045-2322},
doi={10.1038/s41598-019-52737-x},
url={https://doi.org/10.1038/s41598-019-52737-x}
}

@article{gupta,
  author    = {Rahul Gupta},
  title     = {Data augmentation for low resource sentiment analysis using generative
               adversarial networks},
  journal   = {CoRR},
  volume    = {abs/1902.06818},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.06818},
  eprinttype = {arXiv},
  eprint    = {1902.06818},
  timestamp = {Tue, 21 May 2019 18:03:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-06818.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}