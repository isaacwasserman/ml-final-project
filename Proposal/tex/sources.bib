@misc{antoniou,
  doi = {10.48550/ARXIV.1711.04340},
  
  url = {https://arxiv.org/abs/1711.04340},
  
  author = {Antoniou, Antreas and Storkey, Amos and Edwards, Harrison},
  
  keywords = {Machine Learning (stat.ML), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Data Augmentation Generative Adversarial Networks},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{anastasopoulos-neubig-2019-pushing,
    title = "Pushing the Limits of Low-Resource Morphological Inflection",
    author = "Anastasopoulos, Antonios  and
      Neubig, Graham",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1091",
    doi = "10.18653/v1/D19-1091",
    pages = "984--996",
    abstract = "Recent years have seen exceptional strides in the task of automatic morphological inflection generation. However, for a long tail of languages the necessary resources are hard to come by, and state-of-the-art neural methods that work well under higher resource settings perform poorly in the face of a paucity of data. In response, we propose a battery of improvements that greatly improve performance under such low-resource conditions. First, we present a novel two-step attention architecture for the inflection decoder. In addition, we investigate the effects of cross-lingual transfer from single and multiple languages, as well as monolingual data hallucination. The macro-averaged accuracy of our models outperforms the state-of-the-art by 15 percentage points. Also, we identify the crucial factors for success with cross-lingual transfer for morphological inflection: typological similarity and a common representation across languages.",
}

@misc{sigmorphon,
  author = {SIGMORPHON},
  title = {conll2018},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/sigmorphon/conll2018}},
  commit = {490e2e0693241f708670d9d1c56803b754fab7cd}
}

@misc{matching-networks,
Author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
Title = {Matching Networks for One Shot Learning},
Year = {2016},
Eprint = {arXiv:1606.04080},
}

@misc{twin-networks,
  author = {Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan},
  title = {Siamese Neural Networks for One-shot Image Recognition},
  year = {2015},
  publisher = {Carnegie Mellon University},
  howpublished = {\url{https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf}}
}

@article{fewshot,
  Author = {Shruti Jadon},
  Title = {An Overview of Deep Learning Architectures in Few-Shot Learning Domain},
  Year = {2020},
  Eprint = {arXiv:2008.06365},
  Doi = {10.13140/RG.2.2.31573.24803/1},
}

@incollection{shin,
booktitle = {Simulation and Synthesis in Medical Imaging},
copyright = {Springer Nature Switzerland AG 2018},
abstract = {Data diversity is critical to success when training deep learning models. Medical imaging data sets are often imbalanced as pathologic findings are generally rare, which introduces significant challenges when training deep learning models. In this work, we propose a method to generate synthetic abnormal MRI images with brain tumors by training a generative adversarial network using two publicly available data sets of brain MRI. We demonstrate two unique benefits that the synthetic images provide. First, we illustrate improved performance on tumor segmentation by leveraging the synthetic images as a form of data augmentation. Second, we demonstrate the value of generative models as an anonymization tool, achieving comparable tumor segmentation results when trained on the synthetic data versus when trained on real subject data. Together, these results offer a potential solution to two of the largest challenges facing machine learning in medical imaging, namely the small incidence of pathological findings, and the restrictions around sharing of patient data.},
author = {Shin, Hoo-Chang and Tenenholtz, Neil A and Rogers, Jameson K and Schwarz, Christopher G and Senjem, Matthew L and Gunter, Jeffrey L and Andriole, Katherine P and Michalski, Mark},
address = {Cham},
isbn = {3030005356},
issn = {0302-9743},
keywords = {Brain tumor ; Deep learning ; GAN ; Generative models ; Image synthesis ; Magnetic resonance imaging ; MRI ; Segmentation},
language = {eng},
pages = {1-11},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {Medical Image Synthesis for Data Augmentation and Anonymization Using Generative Adversarial Networks},
year = {2018},
}

@article{pix2pix,
  author    = {Phillip Isola and
               Jun{-}Yan Zhu and
               Tinghui Zhou and
               Alexei A. Efros},
  title     = {Image-to-Image Translation with Conditional Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1611.07004},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.07004},
  eprinttype = {arXiv},
  eprint    = {1611.07004},
  timestamp = {Mon, 13 Aug 2018 16:49:05 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/IsolaZZE16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{wang,
  author    = {Guotai Wang and
               Wenqi Li and
               S{\'{e}}bastien Ourselin and
               Tom Vercauteren},
  title     = {Automatic Brain Tumor Segmentation using Cascaded Anisotropic Convolutional
               Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1709.00382},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.00382},
  eprinttype = {arXiv},
  eprint    = {1709.00382},
  timestamp = {Fri, 11 Feb 2022 16:53:28 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-00382.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{sandfort,
author={Sandfort, Veit
and Yan, Ke
and Pickhardt, Perry J.
and Summers, Ronald M.},
title={Data augmentation using generative adversarial networks (CycleGAN) to improve generalizability in CT segmentation tasks},
journal={Scientific Reports},
year={2019},
month={Nov},
day={15},
volume={9},
number={1},
pages={16884},
abstract={Labeled medical imaging data is scarce and expensive to generate. To achieve generalizable deep learning models large amounts of data are needed. Standard data augmentation is a method to increase generalizability and is routinely performed. Generative adversarial networks offer a novel method for data augmentation. We evaluate the use of CycleGAN for data augmentation in CT segmentation tasks. Using a large image database we trained a CycleGAN to transform contrast CT images into non-contrast images. We then used the trained CycleGAN to augment our training using these synthetic non-contrast images. We compared the segmentation performance of a U-Net trained on the original dataset compared to a U-Net trained on the combined dataset of original data and synthetic non-contrast images. We further evaluated the U-Net segmentation performance on two separate datasets: The original contrast CT dataset on which segmentations were created and a second dataset from a different hospital containing only non-contrast CTs. We refer to these 2 separate datasets as the in-distribution and out-of-distribution datasets, respectively. We show that in several CT segmentation tasks performance is improved significantly, especially in out-of-distribution (noncontrast CT) data. For example, when training the model with standard augmentation techniques, performance of segmentation of the kidneys on out-of-distribution non-contrast images was dramatically lower than for in-distribution data (Dice score of 0.09 vs. 0.94 for out-of-distribution vs. in-distribution data, respectively, p{\thinspace}<{\thinspace}0.001). When the kidney model was trained with CycleGAN augmentation techniques, the out-of-distribution (non-contrast) performance increased dramatically (from a Dice score of 0.09 to 0.66, p{\thinspace}<{\thinspace}0.001). Improvements for the liver and spleen were smaller, from 0.86 to 0.89 and 0.65 to 0.69, respectively. We believe this method will be valuable to medical imaging researchers to reduce manual segmentation effort and cost in CT imaging.},
issn={2045-2322},
doi={10.1038/s41598-019-52737-x},
url={https://doi.org/10.1038/s41598-019-52737-x}
}

@misc{cyclegan,
Author = {Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A. Efros},
Title = {Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
Year = {2017},
Eprint = {arXiv:1703.10593},
}

@article{gupta,
  author    = {Rahul Gupta},
  title     = {Data augmentation for low resource sentiment analysis using generative
               adversarial networks},
  journal   = {CoRR},
  volume    = {abs/1902.06818},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.06818},
  eprinttype = {arXiv},
  eprint    = {1902.06818},
  timestamp = {Tue, 21 May 2019 18:03:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-06818.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}